================================================================================
L1/L2 CACHE OPTIMIZATION FOR A64FX INT8 GEMM
================================================================================

ACCURATE CACHE LATENCIES (measured on A64FX):
  L1 hit: 11 cycles
  L2 hit: 27-36 cycles (2.5-3.3× slower)

CACHE SIZES:
  L1: 64 KB per core
  L2: 8 MB shared

================================================================================
CURRENT PERFORMANCE (Baseline 6-row split loading)
================================================================================

D=256:
  ✓ Efficiency: 85.21% of peak (436.3 GOPS)
  ✓ Working set: 4 KB per iteration
  ✓ L1 hit rate: ~90% (estimated)
  ✓ Status: Already near-optimal, compute-bound

D=512:
  ⚠ Efficiency: 67.61% of peak (346.2 GOPS)
  ⚠ Working set: 8 KB per iteration
  ⚠ L1 hit rate: ~75% (estimated)
  ⚠ Status: L2-bound, room for improvement

Gap: D=512 is 17.6% less efficient than D=256

================================================================================
WHY D=512 IS SLOWER (Root Cause)
================================================================================

Working Set Size:
┌──────────────────────────────────────────────────────┐
│ D=256: 4 KB/iter  →  Fits nicely in 64 KB L1       │
│ D=512: 8 KB/iter  →  Too large for good L1 reuse   │
└──────────────────────────────────────────────────────┘

Cache Access Pattern (D=512):
┌──────────────────────────────────────────────────────┐
│ K-group 0-7:   Mostly L1 hits (warm cache)          │
│ K-group 8+:    More L2 accesses (cache thrashing)   │
│                                                      │
│ Result: ~25% of accesses go to L2                   │
│         Each L2 access costs 16-25 extra cycles     │
│         This reduces SDOT throughput significantly  │
└──────────────────────────────────────────────────────┘

The Math:
  L1 hit (11 cyc) × 75% = 8.25 cycles
  L2 hit (31 cyc) × 25% = 7.75 cycles
  Average load latency: 16 cycles per access

  This causes SDOT throughput to drop from 1.70 to 1.35 SDOTs/cycle

================================================================================
OPTIMIZATION STRATEGY 1: SOFTWARE PREFETCHING
================================================================================

Concept:
  Issue prefetch instructions to load data into L1 BEFORE it's needed
  Hide L2 latency (27-36 cycles) by prefetching during computation

Implementation:
  prfm pldl1keep, [address + PREFETCH_DISTANCE]

  PREFETCH_DISTANCE:
    D=256: 16 KB (4 K-groups ahead)
    D=512: 16 KB (2 K-groups ahead)

How It Works:
┌──────────────────────────────────────────────────────┐
│ Without Prefetch:                                    │
│   K-group N:   Load → L2 miss (27-36 cyc) → STALL   │
│   K-group N+1: Compute while waiting                 │
│                                                      │
│ With Prefetch:                                       │
│   K-group N:   Prefetch K-group N+2                  │
│   K-group N:   Load K-group N → L1 hit (11 cyc) ✓   │
│   K-group N+1: Compute while K-group N+2 loads      │
└──────────────────────────────────────────────────────┘

Expected Improvement:
  D=256: +1-3% (already L1-bound, minimal gain)
  D=512: +5-10% (L2-bound, significant gain)

Target Efficiency:
  D=512: 68% → 73-75%

================================================================================
OPTIMIZATION STRATEGY 2: K-GROUP TILING
================================================================================

Concept:
  Process K dimension in smaller tiles to improve L1 cache reuse
  Each tile fits L2 better, provides temporal locality

Implementation:
  Instead of:  for (k=0; k<128; k++) { ... }
  Use:         for (tile=0; tile<4; tile++) {
                 for (k=tile*32; k<(tile+1)*32; k++) { ... }
               }

Tile Size: 32 K-groups per tile
  Tile working set: 32 × 8KB = 256 KB
  Fits L2: 256 KB << 8 MB ✓
  Provides better locality than baseline 1024 KB

How It Works:
┌──────────────────────────────────────────────────────┐
│ Baseline (128 K-groups):                             │
│   Total B data: 1024 KB                              │
│   Exceeds L1 (64 KB)                                 │
│   Poor temporal locality across K-groups             │
│                                                      │
│ K-Tiling (4 tiles × 32 K-groups):                   │
│   Tile 0: Process K-groups 0-31   (256 KB)          │
│   Tile 1: Process K-groups 32-63  (256 KB)          │
│   Tile 2: Process K-groups 64-95  (256 KB)          │
│   Tile 3: Process K-groups 96-127 (256 KB)          │
│                                                      │
│   Each tile fits L2 better                           │
│   Some L1 reuse within tile across N-chunks          │
└──────────────────────────────────────────────────────┘

Expected Improvement:
  D=256: 0% (already fits well)
  D=512: +8-12% (better cache utilization)

Target Efficiency:
  D=512: 68% → 75-78%

================================================================================
OPTIMIZATION STRATEGY 3: COMBINED APPROACH
================================================================================

Use BOTH prefetching AND K-tiling:
  - K-tiling improves L1/L2 utilization
  - Prefetching hides remaining L2 latency within each tile
  - Synergistic effect

Expected Improvement:
  D=512: +12-16% (68% → 78-82%)

This would bring D=512 close to D=256's efficiency!

================================================================================
BENCHMARK RESULTS
================================================================================

Running comprehensive benchmark to measure:
  1. D=256 baseline vs prefetch
  2. D=512 baseline vs prefetch
  3. D=512 baseline vs K-tiling
  4. D=512 baseline vs prefetch+K-tiling (future)

Metrics:
  - CPU cycles per kernel call
  - GOPS (INT8 operations per second)
  - Efficiency (% of 512 GOPS peak)
  - SDOT throughput (SDOTs per cycle)
  - Speedup over baseline

Success Criteria:
  ✓ D=512 efficiency improves by ≥3%
  ✓ SDOT/cycle increases proportionally
  ✓ No correctness issues

================================================================================
EXPECTED OUTCOMES
================================================================================

Best Case:
  D=256: 85.21% → 87% (+2%)
  D=512: 67.61% → 78% (+10%)
  Gap reduced: 17.6% → 9%

Realistic Case:
  D=256: 85.21% → 86% (+1%)
  D=512: 67.61% → 73% (+5%)
  Gap reduced: 17.6% → 13%

Worst Case:
  D=256: No improvement (already optimal)
  D=512: 67.61% → 70% (+2%)
  Hardware prefetcher already helping

================================================================================
IMPLEMENTATION FILES
================================================================================

Baseline Kernels:
  kernel_ffn_6row_gemm_d256.S         - D=256 baseline
  kernel_ffn_6row_gemm.S              - D=512 baseline

Prefetch-Optimized:
  kernel_ffn_6row_gemm_d256_prefetch.S - D=256 + prefetch
  kernel_ffn_6row_gemm_d512_prefetch.S - D=512 + prefetch

K-Tiling:
  kernel_ffn_6row_gemm_d512_ktile.S    - D=512 + K-tiling

Benchmarks:
  bench_cache_opt.c                    - D=512 optimizations
  bench_cache_all.c                    - Comprehensive comparison
  run_cache_all.sh                     - Run all benchmarks

Documentation:
  CACHE_OPTIMIZATION.md                - Detailed technical doc
  CACHE_OPT_SUMMARY.txt                - This file

================================================================================
WHY THIS MATTERS
================================================================================

Impact on Real Workloads:

1. LLM Inference:
   - Qwen3-0.5B uses D=896
   - Qwen3-1.5B uses D=1536
   - Larger D values will suffer same L1 cache issues
   - Optimization techniques scale to larger D

2. Performance Gains:
   - +5-10% speedup = 5-10% more throughput
   - 68% → 75% efficiency = significant improvement
   - Closes gap with smaller D dimensions

3. Production Readiness:
   - Both D=256 and D=512 >65% efficiency
   - Competitive with vendor libraries
   - Hand-optimized for A64FX architecture

================================================================================
NEXT STEPS
================================================================================

After Benchmark Results:
1. Analyze actual improvements
2. Validate with hardware performance counters
3. Measure actual L1/L2 hit rates
4. Consider combined optimizations if beneficial
5. Document final recommendations

Future Work:
1. N-chunk blocking for better A matrix reuse
2. Multi-threading with cache-aware data placement
3. Auto-tuning for different matrix sizes
4. Adaptive strategy selection based on D

================================================================================
